<h1 align="center"> Plant Seedlings Project </h1>
<img width="1000px" height="300px" src="images/out.png"></img>

**Table des mati√®res :**

- [Introduction](#section-1)
  - [Objectifs du pojet](#sous-section-11)
  - [Pr√©sentation du jeu de donn√©es](#sous-section-12)
- [Analyse exploratoire des donn√©es (EDA)](#section-2)
  - [Visualisation des images de diff√©rentes classes](#sous-section-20)
  - [Pixelisation & R√©partition des classes](#sous-section-21)
  - [Statistiques descriptives sur les donn√©es](#sous-section-23)
  - [Distribution des tailles d'images](#sous-section-24)
  - [Analyse de la couleur des images](#sous-section-25)
- [Pr√©traitement des donn√©es](#section-3)
  - [Redimensionnement des images](#sous-section-31)
  - [Normalisation des valeurs de pixel](#sous-section-32)
  - [Augmentation de donn√©es (le cas √©ch√©ant)](#sous-section-33)
  - [Cr√©ation des ensembles d'entra√Ænement, de validation et de test](#sous-section-34)
- [Construction et entra√Ænement du mod√®le](#section-4)
  - [S√©lection de l'architecture du mod√®le (CNN, DNN, MLP etc..)](#sous-section-41)
  - [Mise en place du mod√®lel](#sous-section-42)
  - [Configuration de l'entra√Ænement (hyperparam√®tres, fonction de perte, optimiseur)](#sous-section-43)
  - [Entra√Ænement du mod√®le sur les donn√©es](#sous-section-44)
- [√âvaluation du mod√®le](#section-5)
  - [√âvaluation des performances du mod√®le](#sous-section-51)
  - [Mesures des metriques](#sous-section-52)
  - [Matrice de confusion](#sous-section-53)
  - [Courbes ROC (le cas √©ch√©ant)](#sous-section-54)
  - [Analyse des erreurs de classification](#sous-section-54)
- [Am√©lioration du mod√®le](#section-6)
  - [R√©glage des hyperparam√®tres](#sous-section-61)
  - [Utilisation de mod√®les pr√©-entra√Æn√©s (transfer learning)](#sous-section-62)
  - [Entra√Ænement sur des donn√©es suppl√©mentaires (le cas √©ch√©ant)](#sous-section-63)
  - [R√©√©valuation des performances apr√®s les am√©liorations.](#sous-section-64)
- [Visualisation des r√©sultats](#section-7)
  - [Visualisation des pr√©dictions du mod√®le sur de nouvelles images](#sous-section-71)
- [Conclusion](#section-8)
  - [R√©capitulation des r√©sultats et des conclusions](#sous-section-81)
  - [Possibilit√©s d'extensions ou de travaux futurs](#sous-section-82)
- [R√©f√©rences](#section-9)
  
## <a name="section-1"></a>[Introduction](#section-1) 

<p align="left">Les plantes jouent un r√¥le vital dans notre environnement et notre quotidien. Elles fournissent de la nourriture, de l'oxyg√®ne, et contribuent √† la beaut√© de notre monde naturel. Cependant, la classification et la reconnaissance des diff√©rentes esp√®ces de plantes peuvent s'av√©rer √™tre un d√©fi complexe pour les biologistes  et les chercheurs en sciences de l'environnement et naturel. C'est l√† que l'apprentissage automatique et la vision par ordinateur interviennent pour nous aider √† r√©soudre ce probl√®me si complexe. </p>

Le jeu de donn√©es [Kaggle V2 Plant Seedlings Dataset](https://www.kaggle.com/datasets/vbookshelf/v2-plant-seedlings-dataset) offre une opportunit√© passionnante d'exploration et de comprendre la diversit√© des plantes √† travers une approche informatique bas√© sur du **deep learning**. Compos√© d'une collection d'images de semis de plantes appartenant √† diff√©rentes esp√®ces, ce jeu de donn√©es repr√©sente un d√©fi int√©ressant pour la classification automatis√©e des plantes. En utilisant des techniques de deep learning avanc√©es(CNN, RNN, RCNN etc..) et de traitement d'images (Segmentation d'image), nous pouvons d√©velopper un mod√®le qui sera capable de reconna√Ætre et de classer les plantes en fonction de leurs caract√©ristiques visuelles, d√©tecter √©galement les possibles 
maladies pouvant attaquer ces derni√®re. 

### <a name="sous-section-11"></a>[Ojectifs du projet](#sous-section-11)
<p align="left"> L'objectif de ce projet est de cr√©er un mod√®le de classification d'images capable de distinguer efficacement avec une tr√®s bonne pr√©cision entre les diff√©rentes esp√®ces de plantes pr√©sentes dans le jeu de donn√©es. Pour ce faire, nous allons explorer les images, pr√©traiter les donn√©es, construire un mod√®le d'apprentissage profond, l'entra√Æner sur un ensemble de donn√©es d'entra√Ænement et √©valuer ses performances sur un ensemble de donn√©es de test et validation. Tout au long de ce projet, nous allons √©galement mettre l'accent sur l'analyse des r√©sultats pour mieux comprendre les performances du mod√®le et identifier les d√©fis sp√©cifiques pos√©s par la classification des plantes et voir comment am√©liorer notre mod√®le. </p>

<p align="left">Ce projet ne se limite pas seulement √† la cr√©ation d'un mod√®le de classification, mais il offre √©galement une opportunit√© d'exploration visuelle des donn√©es, de compr√©hension des techniques d'augmentation de donn√©es et d'analyse des erreurs de classification. En fin de compte, notre objectif est d'utiliser les capacit√©s de l'apprentissage automatique pour contribuer √† la recherche en botanique et √† la pr√©servation de la biodiversit√© en identifiant automatiquement les esp√®ces de plantes √† partir d'images.</p>

<p align="left">Dans les sections suivantes, nous allons plonger plus profond√©ment dans les d√©tails du jeu de donn√©es, de l'exploration des donn√©es √† la construction du mod√®le, en passant par l'√©valuation des performances. Nous esp√©rons que ce projet servira de base pour d'autres applications de classification d'images dans le domaine de la botanique et de la biologie.</p>

### <a name="sous-section-12"></a>[Pr√©sentation du jeu de donn√©es](#sous-section-12)

Le jeu de donn√©es [Kaggle V2 Plant Seedlings Dataset](https://www.kaggle.com/datasets/vbookshelf/v2-plant-seedlings-dataset) est un ensemble de donn√©es couramment utilis√© dans le domaine de la vision par ordinateur [REF. 1](https://www.kaggle.com/code/allunia/computer-vision-with-seedlings/notebook) et de l'apprentissage automatique pour la classification d'images de plantes [REF. 2](https://www.researchgate.net/publication/332677611_An_Improved_Deep_Neural_Network_for_Classification_of_Plant_Seedling_Images). Ce jeu de donn√©es est h√©berg√© sur la plateforme [Kaggle](https://www.kaggle.com/), qui est une communaut√© de data scientists et de chercheurs en science des donn√©es.

Comme d√©crit plus haut dans la section <a name="section-11"></a>[Ojectifs du projet](#sous-section-11), l'objectif principal de ce jeu de donn√©es est de permettre la classification automatique des semis de plantes en fonction de leur esp√®ce. Il s'agit d'une t√¢che de classification multi-classe, o√π chaque image est √©tiquet√©e avec l'esp√®ce de plante correspondante.

Le jeu de donn√©es comprend les √©l√©ments suivants :

> [Images]() : Le jeu de donn√©es contient un ensemble d'images en couleur(**RGB** ou **GGBA**) repr√©sentant des semis de plantes. Chaque image est associ√©e √†    une √©tiquette qui indique l'esp√®ce de la plante.

> [Classes]() : Il existe plusieurs classes d'esp√®ces de plantes dans ce jeu de donn√©es. Chaque classe correspond √† une esp√®ce sp√©cifique de plante. Parmi les esp√®ces incluses, on trouve des plantes telles que le ma√Øs, le pissenlit, le ch√©nopode, la renou√©e, la moutarde sauvage, et d'autres *voir tableau ci-dessous*.

> Taille du Jeu de Donn√©es : Le jeu de donn√©es contient un nombre significatif d'images(**5539**), avec plusieurs centaines d'images pour chaque classe. Cependant La taille totale du jeu de donn√©es peut varier en fonction de la version sp√©cifique que vous utilisez. Ici c'est la version V2 du dataset.

| __Noms d'esp√®ces__                    | __Nombre de plantes par esp√®ce__ | __RGBA (RGB + canal alpha)__  |__[Total]()__|
|---------------------------------------|----------------------------------|-----------------------------|------|
| __Black-grass__                       | __309__               | __3__|
| __Charlock__                          | __452__               | __0__|
| __Cleavers__                          | __335__               | __0__|
| __Common Chickweed__                  | __713__               | __0__|
| __Common wheat__                      | __253__               | __0__|
| __Fat Hen__                           | __538__               | __0__|
| __Loose Silky-bent__                  | __762__               | __21__|
| __Maize__                             | __257__               | __0__|
| __Scentless Mayweed__                 | __607__               | __0__|
| __Shepherdoco Purse__                 | __274__               | __0__|
| __Small-flowered Cranesbill__         | __576__               | __0__|
| __Sugar beet__                        | __463__               | __0__|
|  __[Total]()__                        | __[5539]()__                     | __[24]()__      |__[12 esp√®ces]()__|

- Valeurs Statistiques

|__Min__        | __Max__     | __Mean__         | __Med__        | __std__       | __Q1__         | __Q3__       | __IQ__        |
|---------------|-------------|------------------|----------------|---------------|----------------|--------------|---------------|
|  __[253]()__  | __[762]()__ | __[462.6]()__    | __[457.5]()__  | __[179.3]()__ | __[300.3]()__  |__[583.8]()__ | __[283.5]()__ |

## <a name="section-2"></a>[Analyse exploratoire des donn√©es (EDA)](#section-2)
### <a name="sous-section-20"></a>[Visualisation des images de diff√©rentes classes](#sous-section-20)
#### Espace colorim√©trique RGB (Red, Green, Blue) :

![logo](/images/rgb.png)
L'espace RGB est bas√© sur les trois canaux de couleur primaires, √† savoir le **rouge (R), le vert (G) et le bleu (B)**. Chaque pixel d'une image est repr√©sent√© par une combinaison de ces trois canaux, ce qui permet de reproduire une large gamme de couleurs.
L'espace RGB est couramment utilis√© dans le traitement d'images et la vision par ordinateur [REF. 6](https://openaccess.thecvf.com/content_eccv_2018_workshops/w31/html/Hesse_Computer_Vision_for_Medical_Infant_Motion_Analysis_State_of_the_ECCVW_2018_paper.html). Il est adapt√© √† de nombreuses t√¢ches, y compris la classification d'images, la d√©tection d'objets, la segmentation d'images segmentiques[REF. 5](https://towardsdatascience.com/semantic-segmentation-popular-architectures-dff0a75f39d0), [REF. 4](https://nanonets.com/blog/semantic-image-segmentation-2020/).
Il est intuitif, largement utilis√© et convient bien √† de nombreuses applications de vision par ordinateur [REF. 6](https://openaccess.thecvf.com/content_eccv_2018_workshops/w31/html/Hesse_Computer_Vision_for_Medical_Infant_Motion_Analysis_State_of_the_ECCVW_2018_paper.html), [REF. 7](https://www.sciencedirect.com/science/article/abs/pii/S0168169919313249).

#### Espace colorim√©trique RGR2-LAB (CIELAB) :
![logo](/images/out.png)
L'espace LAB est un espace colorim√©trique qui est con√ßu pour √™tre perceptuellement uniforme, ce qui signifie que les distances entre les couleurs dans cet espace sont plus coh√©rentes avec la perception humaine de la couleur que dans l'espace RGB. Il se compose de trois composantes : **la luminosit√© (L), l'axe vert-rouge (A) et l'axe bleu-jaune (B)**.
L'espace LAB est souvent utilis√© pour des t√¢ches o√π la perception de la couleur par l'≈ìil humain est importante. Il est fr√©quemment utilis√© en imagerie m√©dicale, en conception graphique et en analyse de la couleur.
Il est adapt√© √† des t√¢ches o√π la pr√©cision de la correspondance des couleurs est cruciale. L'espace LAB est ind√©pendant du p√©riph√©rique, ce qui signifie qu'il est moins sensible aux variations de couleur dues aux diff√©rents √©crans et appareils.

L'utilisation de deux espaces colorim√©triques (RGB et LAB) peut √™tre int√©ressante pour explorer diff√©rentes approches de pr√©traitement des images et √©valuer comment ces espaces affectent les performances de votre mod√®le.  Nous allons voir comment l'utilisation de l'espace RGR2-LAB 
peut faciliter la segmentation de l'image s√©mantique, et d√©bruit√© une image avec une √©fficacit√© redoutable.

### <a name="sous-section-21"></a>[Pixelisations & R√©partition des classes](#sous-section-21)
![logo](/images/hist_bar.png)

Les deux graphiques ci-dessus pr√©sentent la r√©partition du nombre de pixels et du nombre de plantes par esp√®ce. De ces graphiques, deux observations importantes se d√©gagent :

> √âtant donn√© que la taille d'un pixel est d√©finie comme $pixel = (largeur * hauteur)$, on constate une concentration des valeurs autour de l'intervalle [0.1, 0.4] mega pixels, indiquant une certaine h√©t√©rog√©n√©it√© dans les donn√©es, ainsi que la pr√©sence de quelques valeurs aberrantes donc la plus grande valeur est de 3.6 Mega Pixels.

> On remarque √©galement que le nombre d'exemplaires varie d'une esp√®ce √† l'autre avec une certaine disparit√© dans l'histogramme en bar.

Pour obtenir un mod√®le de deep learning performant, il est essentiel que tous les √©chantillons aient la m√™me taille(normalisation du dataset). Par cons√©quent, la normalisation de ce jeu de donn√©es est n√©cessaire, tout comme l'utilisation de la data augmentation(**voir plus tard**).

Afin d'atteindre l'objectif d'une taille d'√©chantillonnage uniforme, la normalisation des donn√©es est cruciale. La data augmentation joue √©galement un r√¥le fondamental dans ce processus. En utilisant des techniques de data augmentation telles que la rotation, le redimensionnement et le recadrage, nous pouvons g√©n√©rer des versions modifi√©es des images existantes, les rendant coh√©rentes en termes de taille.

Cela permet non seulement d'am√©liorer la qualit√© et la diversit√© du jeu de donn√©es, mais aussi d'augmenter la robustesse du mod√®le de deep learning en l'entra√Ænant sur une vari√©t√© d'angles et de perspectives des donn√©es. Ainsi, un mod√®le form√© sur un jeu de donn√©es normalis√© et augment√© est plus susceptible de g√©n√©raliser correctement lorsqu'il est confront√© √† de nouvelles donn√©es.

## Strategies:

## Methods :

## Acknowledgement :

## <a name="section-1"></a>[Analyse exploratoire des donn√©es (EDA)](#section-2)
- [REF. 1](https://www.kaggle.com/code/allunia/computer-vision-with-seedlings/notebook)
- [REF. 2](https://www.researchgate.net/publication/332677611_An_Improved_Deep_Neural_Network_for_Classification_of_Plant_Seedling_Images)
- [REF. 3](https://fr.wikipedia.org/wiki/Segmentation_d%27image)
- [REF. 4](https://nanonets.com/blog/semantic-image-segmentation-2020/)
- [REF. 5](https://towardsdatascience.com/semantic-segmentation-popular-architectures-dff0a75f39d0)
- [REF. 6](https://openaccess.thecvf.com/content_eccv_2018_workshops/w31/html/Hesse_Computer_Vision_for_Medical_Infant_Motion_Analysis_State_of_the_ECCVW_2018_paper.html)
- [REF. 7](https://www.sciencedirect.com/science/article/abs/pii/S0168169919313249)
## Authors : 
* __**```Dr. Ir√©n√© A.E```**__
* __**```Olivier M.```**__ 
* __**```Hassan Z.```**__
* __**```Gilles D.P```**__

## ü§ù Support 
Give a ‚≠ê if you like this project!

## License 
Copyrihght ¬© 2023 __**Ir√©n√© A.E, Olivier M., Hassan Z., Gilles D.P**__

This project is licensed under [MIT License](https://github.com/amiehe-essomba/Plant_Seedlings_ds_Project/blob/Plant_Seedlings/LICENSE)

[citation](https://vision.eng.au.dk/plant-seedlings-dataset/)